{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN을_활용한_간단한_주식예측.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0ABM1xqe4b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.layers import Input, RNN , Layer, Dense\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.optimizers import adam \n",
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "import pandas as pd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUG4qy7y-9-V",
        "colab_type": "text"
      },
      "source": [
        "[https://investing.com](https://www.investing.com/equities/kb-financial-group-historical-data)\n",
        "\n",
        "\n",
        "KB 은행, 주식 데이터 다운로드\n",
        "![Imgur](https://i.imgur.com/k2F31Df.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkdbzjB7RDJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 종가 데이터 가져오기\n",
        "print(pd.read_csv('kb_stock_data.csv').head())\n",
        "stock_data = pd.read_csv('kb_stock_data.csv')['Price']\n",
        "\n",
        "# String to float\n",
        "def _fn(str_):\n",
        "    return float(str_.replace(',', '').replace('.',''))\n",
        "stock_data = list(map(_fn, stock_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6IR-OFk-yAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_time_step = 5 \n",
        "\n",
        "# stock data 을 2017~ 2019 년도 순으로 재배열 한다. \n",
        "rev_stock_data = stock_data[::-1]\n",
        "\n",
        "# train dataset 과 validation dataset 을 나눈다. \n",
        "# 2019년 12월 데이터셋은 Test 데이터를 사용한다. \n",
        "\n",
        "test_dataset = rev_stock_data[-19:]\n",
        "train_dataset = rev_stock_data[:-19]\n",
        "\n",
        "def data_slicer(sample_array, n_time_step):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        [1, 2, 3, 4, 5, 6, 7, 8, 9,]\n",
        "        <--------->\n",
        "            <-------->\n",
        "                <------->\n",
        "        xs : [[1,2,3,4], [4,5,6,7], [7,8,9,10]]\n",
        "        *window stride 는 1로 고정.\n",
        "    \n",
        "    Args:\n",
        "        sample_array : 1D > array \n",
        "        n_time_step : int \n",
        "    \n",
        "    Return:\n",
        "        divided_array: \n",
        "\n",
        "    \"\"\"\n",
        "    n_move = len(sample_array) - n_time_step + 1\n",
        "    sliced_array = []\n",
        "    for idx in range(n_move):\n",
        "        sliced_array.append(sample_array[idx:idx+n_time_step])\n",
        "    return np.asarray(sliced_array)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A9XXl7Q2A9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# slice dataset\n",
        "sliced_train = data_slicer(train_dataset, n_time_step + 1)\n",
        "\n",
        "# generate train dataset / test dataset \n",
        "train_xs = sliced_train[:, :n_time_step]\n",
        "train_ys = sliced_train[:, n_time_step:]\n",
        "\n",
        "# RNN model need 3D Tensor \n",
        "train_xs = np.expand_dims(np.array(train_xs), axis=-1)\n",
        "\n",
        "# normalization \n",
        "train_max = np.max(train_xs)\n",
        "train_min = np.min(train_xs)\n",
        "norm_train_xs = (train_xs - train_min ) / (train_max - train_min)\n",
        "norm_train_ys = (train_ys - train_min ) / (train_max - train_min)\n",
        "\n",
        "\n",
        "# normalization checking \n",
        "norm_train_ys.min(), norm_train_ys.max(), norm_train_xs.min(), norm_train_xs.max(), \n",
        "print(train_xs.shape, train_ys.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1OakYN_ZRjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_dataset \n",
        "sliced_test = data_slicer(test_dataset, n_time_step + 1)\n",
        "\n",
        "# generate train dataset / test dataset \n",
        "test_xs = sliced_test[:, :n_time_step]\n",
        "test_ys = sliced_test[:, n_time_step:]\n",
        "\n",
        "# RNN model need 3D Tensor \n",
        "test_xs = np.expand_dims(np.array(test_xs), axis=-1)\n",
        "\n",
        "# normalization\n",
        "norm_test_xs = (test_xs - train_min ) / (train_max - train_min)\n",
        "norm_test_ys = (test_ys - train_min ) / (train_max - train_min)\n",
        "\n",
        "# normalization checking \n",
        "print(norm_test_ys.min(), norm_test_ys.max(), norm_test_xs.min(), norm_test_xs.max(), )\n",
        "print(norm_test_xs.shape, norm_test_ys.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxonKssYfcj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNCell(Layer):\n",
        "    def __init__(self, n_units, **kwargs):\n",
        "        self.state_size = n_units\n",
        "        self.n_units = n_units\n",
        "        super(RNNCell, self).__init__(**kwargs)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.w_x = self.add_weight(name='w_x',\n",
        "                        shape=(input_shape[-1], self.n_units),\n",
        "                        initializer=tf.initializers.glorot_normal())\n",
        "        self.w_h = self.add_weight(name='w_h',\n",
        "                        shape=(self.n_units, self.n_units),\n",
        "                        initializer=tf.initializers.orthogonal())\n",
        "        self.b = self.add_weight(name='b',\n",
        "                        shape=(self.n_units),\n",
        "                        initializer=tf.initializers.zeros())\n",
        "        super(RNNCell, self).build(input_shape)\n",
        "    \n",
        "    def call(self, inputs, states):\n",
        "        prev_state = states[0]\n",
        "        z = tf.matmul(inputs, self.w_x) + tf.matmul(prev_state, self.w_h) + self.b \n",
        "        a = tf.tanh(z)\n",
        "        return a, [a]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5RRr6mgqVEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.python.keras.layers import Input, RNN , Layer, Dense\n",
        "tf.reset_default_graph()\n",
        "inputs = Input(shape=(n_time_step, 1))\n",
        "hidden = RNN(RNNCell(n_units=300), return_state=True)(inputs)\n",
        "pred = Dense(1, activation='linear')(hidden[0])\n",
        "model = Model(inputs, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm5X2ciFvCMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mse', optimizer=adam(0.0001))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gYF_UA4zSaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(norm_train_xs, norm_train_ys, batch_size=128, epochs=240)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMiJn-g45D7f",
        "colab_type": "text"
      },
      "source": [
        "## Prediction Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBhuAGXyzmmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_norm_hat = model.predict(norm_train_xs)\n",
        "y_hat = y_norm_hat* (train_max - train_min) + train_min"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMlyGze7VJGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "plt.scatter(np.arange(len(train_ys)), y_hat, s=3, alpha=0.5, label='pred')\n",
        "plt.scatter(np.arange(len(train_ys)), train_ys, s=3, alpha=0.5, label='true')\n",
        "plt.legend()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRZO4Z8A5QiZ",
        "colab_type": "text"
      },
      "source": [
        "## Prediction Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLMGfgv_WA4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_norm_hat = model.predict(norm_test_xs)\n",
        "test_hat = test_norm_hat * (train_max - train_min) + train_min"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEwdH8P0ZvNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(np.arange(len(test_ys)), test_hat, s=16, alpha=0.5, label='pred')\n",
        "plt.scatter(np.arange(len(test_ys)), test_ys, s=16, alpha=0.5, label='true')\n",
        "plt.legend()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc3xunte4zfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}